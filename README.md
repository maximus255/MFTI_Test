<!-- markdow basic commands here  https://www.markdownguide.org/basic-syntax/ -->
# Тестовое задание

Код выполнен в виде jupyter ноутбука и должен запускаться на Google CoLab сервисе. Но может быть запущен и локально (если позволяет видеокарта). Это минимальный код, необходимый для машинного обучения в задаче семантической сегментации - без аугментации, без TensorBoard, без подбора макропараметров и т.п. 

## Установка
Для локального использования нужно установить необходимые зависимости, запустив  
`pip install -r requirements.txt` 
Предполагается, что большинство стандартных библиотек уже установлены, в том числе и jupyter.  
В корневую директорию репозитория нужно развернуть Pascal-part датасет. (можно использовать другое местоположение датасета, но путь до него нужно будет указать в ноутбуке).  
  

Для запуска на Google CoLab, нужно скопировать Pascal-part на GoogleDrive в папку, путь на которую прописан в ноутбуке. GoogleDrive будет примонтирован по ходу выполнения скрипта. 

## Структура ноутбука
Ноутбук ***MFTI_Test.ipynb*** содержит код, позволяющий запустить процесс обучения нейросети. Модель сети загружается из библиотеки PyTorch *segmentation_models_pytorch*. Не обязательно использовать именно указанную в ноутбуке модель (об этом далее).  
В качестве функции потерь используется *CrossEntropy*, есть вариант с самодельным классом UoILoss  
Для чтения данных из датасета используется класс *PascalDataset*. Несколько ячеек отвечают за тестирование работы этого класса и за растрирование картинок из датасета. 
![LossFunction](imgs/plot0.png)  
В принципе, весь технический код может быть удален без последствий для обучения сетки. Я его оставил просто как иллюстрацию того, как продвигался рабочий процесс. Также вспомогательные классы и функции могут быть убраны в подмодули.  
Метрики для оценки качества обучения (без учета класса фона) *MeanUoI<sup>0</sup>-MeanUoI<sup>2</sup>* взяты из PyTorch библиотеки *torchmetrics.segmentation*. Также есть функции для перевода тензоров, содержащих классы всех частей тела, в обобщающие классы.

## Обучение
Для запуска процесса обучения достаточно просто выполнить код ноутбука. На моей локальной машине видеокарта слабая, поэтому код выполняется только на ЦПУ. На CoLab код может быть выполнен и на ГПУ. 
Можно проводить обучение на всем датасете или на ограниченной его части - для скорости и проверки работоспособности кода. Чтобы проводить обучение на ограниченном датасете нужно задать значения переменных limit (для train датасета) и limit_test (для валидационного). Если задать эти переменные как None, то будет производиться обучение по всему датасету. Также можно задать количество эпох, размер бачей и тп.  
На CoLab был запущен цикл обучения на ограниченном датасете из 1000 картинок. Результатом ожидаемо стало **переобучение** модели. Процесс обучения на всем датасете не был закончен, потому, что у CoLab закончилось бесплатное время для ГПУ.
![LossFunction](imgs/plot.png)
![MeanUoIs](imgs/plot1.png)

## Возможные дальнейшие шаги для улучшения результата  
Если бы это был реальный проект, то я бы сделал следующие шаги, чтобы получить наилучший результат.
1. ### Выбор модели и функции потерь.
Для теста я взял одну из самых маленьких моделей для семантической сегментации (надеялся, что она будет работать на моей слабой локальной машине, но нет). Но на практике, это вопрос требующий исследования. Только библиотека *segmentation_models_pytorch* содержит десятки вариантов разных сеток. Плюс, разные варианты функций потерь, как стандартные, так и кастомные. Я бы использовал либо сервис WaitAndBias.com чтобы **автоматически** повторить процесс обучения много раз на датасете ограниченного размера с сразными комбинациями используемых моделей и функций потерь. По результатам, я имел бы наглядный график в W&B сервисе, который показывал бы, какое сочетание модели и функции потерь наиболее перспективно для дальнейшего исседования.  
Либо, как альтернативу W&B, я использовал бы TensorBoard сервис и скрипт для генерации разных комбинаций модель+лосс. Результатом тоже стало бы сочечание модель+функция потерь, наилучшим образом показавшая себя с данным датачетом.

2. ### Подбор макропараметров.
Имея наилучшее сочетание модели и функции потерь, на следующем шаге я бы использовал предыдущий подход и запустил бы серию экспериментов для автоматического подбора наилучшей комбинации макропараметров процесса обучения: Оптимизатор, ЛёрнингРейт, размер бача и тп.  
Шаги 1 и 2, теоритически могли бы быть выполнены совместно, но на практике это ведет к очень большому количеству вариантов. Поэтому, приходится идти на некоторый компромис ради скорости, возможно в ущерб качеству.

3. ### Аугментация\Альбументация
На этом этапе мы можем попробовать запустить процесс обучения нашей сетки на всем датасете, имея некоторую наилучшую комбинацию разных макропараметров. Если бы это сразу привело к достижению желаемого результата, то это было бы прекрасно. Но, скорее всего, этого не случиться. Слишком маленький размер датасета. На помощь может придти процесс аугментации имеющегося набора картинок. Эта задача решается просто, путем добавления в наш класс для чтения датасета стандартных трансформаций для аугментации\альбументации картинок (и масок с классами) случайным образом на каждой эпохе. Это позволит в конце концов обучить нашу нейросеть до требуемого качества даже на нашем ограниченном наборе картинок.  
После чего, полученный файл .pth может быть либо использован как есть в стандартном скрипте для инференса, или при необходимости, он может быть конвертирован в другой нужный формат для дальнейшего использования, например, на устройстве.

## Заключение.
Представленный код позволяет обучать нейросеть для семантической сегментации по данному датасету и оценивать качество обучения по требуемым метрикам.  
Хотя процесс обучения сети не был завершен по техническим причинам (исчерпание лимити времени на Google CoLab), но, при наличии  компьютера с современной видеокартой, процесс обучения может быть легко повторен.  
Также указаны шаги, которые должны быть выполнены при работе с реальной задачей, а не с тестовым заданием.




